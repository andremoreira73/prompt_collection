"""
This is a good example on hos to influence "weaker" models like 4o-mini to follow a certain format. 
This was coded before structured outputs was available, so it is a legacy code.
"""


############################################
def prompt_decision(topic, decision_context) -> str:
    # The prompt telling the LLM to decide if a text is worth downloading or not
    # we are passing the decision_examples_snippets as a list
    # Note this is purposely **not** using structured outputs

    # copy **EXACTLY** the prompt head we used for the fine tuning - do not change without fine tuning again!
    prompt = f"""
    You are a helpful assistant that can decide if a given text is worth reading or not.
    After the mark '///:' is a text snippet about {topic}. 
    
    Your job is to carefully read the text snippet after the mark '///:' and understand if it discusses 
    about anything related to {decision_context} in the area of {topic}.

    If this is the true, you must respond <True>.
    If this is not true, you must respond <False>.
    If you cannot decide, respond <Undecided>.

    You are only allowed to answer <True>, <False> or <Undecided>.
    You are only allowed to answer <True>, <False> or <Undecided>.
    You are only allowed to answer <True>, <False> or <Undecided>.

    ///:
    """

    return(prompt)
